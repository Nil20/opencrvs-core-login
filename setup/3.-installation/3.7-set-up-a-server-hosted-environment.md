# 3.7 Set-up a server-hosted environment

This outlines the process to setup and deploy OpenCRVS on a remote server environment for Staging (developer testing), Quality Assurance or live Production use.

#### Decide on the size of your deployment

Decide on the size of your deployment. OpenCRVS supports deploying to 1 server, but this is only supported for a testing, staging or a QA environment.

Alternatively, OpenCRVS supports deploying to 3 servers creating Mongo replica sets for managing a production environment at a normal scale.

Finally, OpenCRVS supports deploying to 5 servers creating Mongo replica sets for managing a production environment at a large scale.

If you wish to enable an automated backup from production onto another server, you will need an additional server for this.

#### Provision your IP addresses with SSH access

1. Using your hosting provider, setup 1, 3 or 5 Ubuntu server nodes with an additional backup server node should you require this option. OpenCRVS can be deployed on a cluster of 3 or 5 server nodes in production and 1 server node in a demo, staging or QA environment, each with the following minimm specification:

8 GB Memory (preferrably 16 GB) / 160 GB Disk / Ubuntu 18.04.3 (LTS) x64

1. Decide which of your IP addresses will be the **Manager Node** This server will be the manager in the Docker Swarm and the main server used to control load balancing.
2. Add your users GIT SSH keys to all nodes, and ensure that you take a note of each server's **hostname**

This is a handy command to copy any SSH keys you use on Git into a server's .ssh/authorized\_keys file.

```
curl https://github.com/<git-user>.keys >> ~/.ssh/authorized_keys
```

1. For production deployments of 3 or 5 servers, or where you are provisioning a server backup, ensure the manager node can ssh into all the other worker and backup nodes.

SSH into manager node and create an ssh key. Press Enter for defaults and no passphrase

```
ssh-keygen
```

Print the key for copying:

```
cat ~/.ssh/id_rsa.pub
```

Copy the key and exit the manager node.

SSH into the 2 or 4 worker nodes to add the key into the .ssh/authorised\_keys for all nodes

```
echo "<manager-node-public-key>" >> ~/.ssh/authorized_keys
```

If you are setting up a backup server, ensure that the manager node can ssh into that too. SSH into the backup node to add the key into its .ssh/authorised\_keys file.

SSH into the manager, and confirm that you can SSH into all nodes from the manager.

You are now ready to exit all nodes and run the Ansible command from your local environment.

#### Install Ansible to automate the dependency installation, firewall and optional backup

Ansible is required to run the server setup. Ansible is an IT automation tool and the script we provide will install all the dependencies onto your nodes and configure a secure firewall, open required ports and provision the optional automated backup of OpenCRVS for use in production.

Ansible should be installed on your local machine. Installation instructions are [here](https://docs.ansible.com/ansible/latest/installation\_guide/intro\_installation.html). Also ensure that you have ssh access with the root user to all the servers that you are trying to configure.

1. Create an account on [Dockerhub](https://hub.docker.com/) as Ansible will require your username and password in order to login.
2. Duplicate the **example-X.ini** inventory\_file of choice depending if you are deploying to 1, 3 or 5 servers.

If you are only deploying to 1 server, you need to make a copy of the [example-1.ini](https://github.com/opencrvs/opencrvs-core/blob/master/infrastructure/server-setup/example-1.ini) file to run with the Ansible [playbook-1.yml](https://github.com/opencrvs/opencrvs-core/blob/master/infrastructure/server-setup/playbook-1.yml) explained below.

**Only 1 server is not supported for production deployments**

If you are deploying to a standard production deploymet of 3 servers, you need to make a copy of the [example-3.ini](https://github.com/opencrvs/opencrvs-core/blob/master/infrastructure/server-setup/example-3.ini) file to run with the Ansible [playbook-3.yml](https://github.com/opencrvs/opencrvs-core/blob/master/infrastructure/server-setup/playbook-3.yml) explained below.

If you are deploying to 5 servers, you need to make a copy of the [example-5.ini](https://github.com/opencrvs/opencrvs-core/blob/master/infrastructure/server-setup/example-5.ini) file to run with the Ansible [playbook-5.yml](https://github.com/opencrvs/opencrvs-core/blob/master/infrastructure/server-setup/playbook-5.yml) explained below.

You will be required to uncomment some lines to enter the IP addresses and hostnames, e.g.:

```
;manager1 ansible_host="ENTER YOUR MANAGER HOST IP"
```

becomes:

```
manager1 ansible_host="159.223.11.243"
```

... and:

```
;data1_hostname=ENTER_HOSTNAME_1
```

becomes:

```
;data1_hostname=farajaland-staging
```

1. Using a strong password generator, such as [1Password](https://1password.com/) you should create and **safely store** a master mongo password and encrypt\_passphrase along with an elasticsearch superuser password in order to prepare these required parameters. If you want to make use of the provided automated Github Actions for automated continuous deployment from your Git repo, you will need to set the same details as Github Action Secrets, so make sure that you save them for future use:

**Required parameters:**

Call the Ansible command below passing these required paramters.

dockerhub\_username dockerhub\_password mongodb\_admin\_username mongodb\_admin\_password elasticsearch\_superuser\_password encrypt\_passphrase

**Optional parameters:**

For the optional automated daily external data backup to another server, these parameters must be prepared. You can :

external\_backup\_server\_ip external\_backup\_server\_user external\_backup\_server\_ssh\_port external\_backup\_server\_remote\_directory

If you have a [Papertrail](https://www.papertrail.com/) account, OpenCRVS can automatically export system logs to Loggly using this parameter:

papertrail\_token

1. Ansible playbooks are run like this **at a minimum**:

If you are on the root directory of the opencrvs-core repository, navigate to the server-setup folder:

```
cd infrastructure/server-setup
```

Now you can run the playbook like this, substituting the paramters as required:

```
ansible-playbook -i <inventory_file> <playbook_file> -e " \
dockerhub_username=<your_username> \
dockerhub_password=<your_password> \
mongodb_admin_username=opencrvs-admin \
mongodb_admin_password=<secure password you generated> \
elasticsearch_superuser_password=<secure password you generated> \
encrypt_passphrase=<a_strong_passphrase> \
encrypt_data=True"
```

Or with all the possible **optional props**:

```
ansible-playbook -i <inventory_file> <playbook_file> -e " \
dockerhub_username=<your_username> \
dockerhub_password=<your_password> \
mongodb_admin_username=opencrvs-admin \
mongodb_admin_password=<secure password you generated> \
elasticsearch_superuser_password=<secure password you generated> \
encrypt_passphrase=<a_strong_passphrase> \
encrypt_data=True \
external_backup_server_ip=<your_external_backup_server_ip> \
external_backup_server_user=<your_external_backup_server_user> \
external_backup_server_ssh_port=<your_external_backup_server_ssh_port> \
manager_production_server_ip=<your_manager_production_server_ip> \
external_backup_server_remote_directory=<your_external_backup_server_remote_directory>"
```

Once this command is finished the servers are prepared for an OpenCRVS deployment. You can read more about the external backups in the **Emergency Backup & Restore** section

#### Create Docker Secrets

Before the deployment can be done a few secrets need to be created and manually added to the docker swarm. [Docker secrets](https://docs.docker.com/engine/swarm/secrets/) are used as a secure alternative to serving passwords in environment variables without using .env files

Using a strong password generator service such as [1Password](https://1password.com/) you should create and safely store the required passwords as you will need them regularly in other steps such as when populating your country configuration database.

**ssh into the manager server and run the following commands, replacing the values with the actual secrets:**

1. Running the following lines saves the login details to OpenHIM as Docker secrets. You will have created this password when setting up your country configuration. The username will likely be the default: root@openhim.org

```
printf "<openhim-user>" | docker secret create openhim-user -
printf "<openhim-password>" | docker secret create openhim-password -
```

1. The next secrets store the choice of SMS provider and connection details. Currently you can only choose between [Clickatell](https://www.clickatell.com/) and [Infobip](https://www.infobip.com/). In a future version of OpenCRVS, we intend to refactor out the entire notification microservice from core into the country configuration server so that you can choose any communication provider and method that you wish. Currently if you would like to set up a different provider we would really appreciate it if you open a pull request.

a) In your country configuration look at the file docker-compose.countryconfig.prod-deploy.yml file. You will notice that environment variables are passed to the notification service from this compose file. Set the choice of provider in the SMS\_PROVIDER environment veriable. You can set the choice to be **clickatell** or **infobip**

```
- SMS_PROVIDER=infobip
```

b) Depending on your choice of provider, you need to set the following Docker secrets

```
# In Zambia we have used Clickatell, we have found good Telco coverage in Africa with this provider
printf "<clickatell-user>" | docker secret create clickatell-user -
printf "<clickatell-password>" | docker secret create clickatell-password -
printf "<clickatell-api-id>" | docker secret create clickatell-api-id -

# For Bangladesh we used Infobip, we have found good Telco coverage in Asia with this provider
printf "<infobip-gateway-endpoint>" | docker secret create infobip-gateway-endpoint -
printf "<infobip-api-key>" | docker secret create infobip-api-key -
printf "<infobip-sender-id>" | docker secret create infobip-sender-id -
```

After creating the secrets make sure the commands are removed from the shell history by running `history -c`

Also note, if depending on your setup you can't ssh into the manager as **root** you will need to add your ssh user to Docker to be able to run docker commands:

```
sudo groupadd docker
sudo usermod -aG docker $USER
```

Note: the Ansible script will install the UFW firewall, however, Docker manages it's own iptables. This means that even if there are UFW rules to block certain ports these will be overridden for ports where Docker is publishing a container port. Ensure only the necessary ports are published via the docker-compose files. Only the necessary ports are published by default, however, you may want to check this when doing security audits.

#### Set up an SMTP server for OpenCRVS monitoring alerts

We use [Elastalert](https://elastalert.readthedocs.io/en/latest/), in tandem with ElasticSearch and Kibana to monitor the health of the OpenCRVS stack in production. In order for OpenCRVS to alert your Technical System Administrator of any memory or hardware issues, we have set up email notifications as the Elastalert option. So you need to have an SMTP service available. [Google offers SMTP services for free](https://kinsta.com/blog/gmail-smtp-server/) linked to a Gmail account, but there are countless other paid for SMTP services such as [Mailchimp](https://mailchimp.com/). You will need to know your SMTP host, port, username and password. We have hardcoded the service to use SMTP SSL by default.

#### Manage DNS for your chosen domain

Using your domain management system, A records will need to be created for all the services which are publicly exposed.

This also enables the Traefik SSL cert to be succcessfully generated. The SSL cert is signed by [LetsEncrypt](https://letsencrypt.org/) in the infrastructure/traefik.toml config file by default. If you wish to use a different SSL cert provider, you can amend the code there to do so.

Create A records for each of the following, with a TTL of 1 hour that forward the URL to your manager node's external IP address

\<your\_domain> api.\<your\_domain> auth.\<your\_domain> config.\<your\_domain> countryconfig.\<your\_domain> gateway.\<your\_domain> kibana.\<your\_domain> login.\<your\_domain> openhim-api.\<your\_domain> openhim.\<your\_domain> register.\<your\_domain> webhooks.\<your\_domain>

#### Run the deploy Github Ation

The best way to deploy OpenCRVS to your stack is by using our supplied Github Actions in the country configuration repo.

1. First you need to ensure that you set up at least one, or optionally all, of the following Git [environments](https://docs.github.com/en/actions/deployment/targeting-different-environments/using-environments-for-deployment):

These environments allow you to provision different subdomains, secrets and optional deployment properties depending on your chosen deployment environment.

a) **staging** - A useful environment for developers, where the environment variable NODE\_ENV is set to **development** and you can create test user accounts with a 6 zero "000000" 2FA code during login.

b) **qa** - A quality assurance/pseudo production environment for software testers, where the environment variable NODE\_ENV is set to **procuction** and a secondary exception variable QA\_ENV is set to **true**, so that you can create test user accounts with a 6 zero "000000" 2FA code during login but be able to test all other production features.

c) **production** - A live environment, where NODE\_ENV is set to **production** & QA\_ENV is set to **false**, SMS random 2FA is enabled.

1. You need to create the following [Github secrets](https://docs.github.com/en/codespaces/managing-codespaces-for-your-organization/managing-encrypted-secrets-for-your-repository-and-organization-for-codespaces) for the usernames and passwords you created earlier when provisioning the servers using Ansible, along with other secrets Github will use to SSH into your servers, set the Traefik SSL hostname, connect to [Dockerhub](https://hub.docker.com/) etc.

These secrets below can be set as global repository secrets in Github as they apply to all environments:

ELASTICSEARCH\_SUPERUSER\_PASSWORD KIBANA\_PASSWORD KIBANA\_USERNAME MONGODB\_ADMIN\_PASSWORD MONGODB\_ADMIN\_USER DOCKER\_USERNAME - Your [Dockerhub](https://hub.docker.com/) username DOCKER\_PASSWORD - Your [Dockerhub](https://hub.docker.com/) password DOCKERHUB\_ACCOUNT - The name of your Dockerhub account or organisation that forms the URL to your country config docker image before the slash. e.g: ocrvs DOCKERHUB\_REPO - The name of your Dockerhub repository .. the name of your country config docker image after the slash. e.g. opencrvs-farajaland SMTP\_HOST SMTP\_PORT SMTP\_USERNAME SMTP\_PASSWORD ALERT\_EMAIL - the email address of your Technical System Administrator who should receive server health alerts

The following secrets likely change for each environment so they should be duplicated as environment secrets in Github

Github needs a [deployment SSH key](https://docs.github.com/en/developers/overview/managing-deploy-keys) to be enabled. FYI we use [this Github action](https://github.com/shimataro/ssh-key-action) to connect.

KNOWN\_HOSTS - You will need a copy of the KNOWN\_HOSTS line in **.ssh/known\_hosts** relevant to the host domain name for your environment. This will have been generated using a test SSH connection using your key SSH\_KEY - Note: This is a copy of the **id\_rsa** file for your deploy key ... Not the id\_rsa.pub! STAGING\_DOMAIN or QA\_DOMAIN or PRODUCTION\_DOMAIN - the host **domain name** (without www!) for your environment. **You must make sure that you can ping this domain and that the ping resolves to your manager server's IP address.** If this does not resolve, there must be a problem with your A record configuration explained previously REPLICAS - The number of replicas: **1, 3 or 5** depending on the setup introduced above. FACTORY\_RESET - For production, set to **no** as you do not want each deployment to factory reset OpenCRVS. This is a process which deletes any registrations or users made and restores reference data. For staging and qa, you can optionally set this to **yes** and OpenCRVS will reset on each deploy, deleting registratons and restoring all data. A useful option for developers and testers.

1. With these secrets the first Github action is set to automatically run on your country configuration repository whenever code is pushed to a branch named master, main or develop. This action will build and push your Docker image to Dockerhub. **The image will be tagged with the short Git commit hash. This is important to refer to and use in the next step.**

**Publish image to Dockerhub: .github/workflows/publish-to-dockerhub.yml**

1. When the previous action has completed, you can deploy to your server with this action.

a) You will be required to select the environment to deploy to. b) You will be required to enter the short Git hash that is tagged in the OpenCRVS Core release of choice c) You will be required to enter the short Git hash that is tagged in your country configuration image created by the previous "Publish image to Dockerhub" action

**Deploy: .github/workflows/deploy.yml.yml**

Once the deployment is complete, wait a couple of minutes before browsing to OpenCRVS as it can take a little while for the Docker images to start up. If this is your first deployment, wait about 15 minutes as Docker must download them first.
